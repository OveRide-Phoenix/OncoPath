{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b24a4fe-7d86-4a1d-b57f-2980d548b9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import label, regionprops\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from monai.transforms import LoadImage, EnsureChannelFirst, ScaleIntensity, EnsureType, Compose, Resize\n",
    "from monai.data import Dataset, DataLoader\n",
    "from monai.networks.nets import UNet\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from pydicom import dcmread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a11df348-36de-44db-ad26-ba0cea91b179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "base_dir = r\"D:\\PROJECTS_FINAL\\Cancer Treatment Prediction\\final stuff\\manifest-1732777365016\"\n",
    "metadata_file_path = os.path.join(base_dir, \"metadata.csv\")\n",
    "output_dir = os.path.join(base_dir, \"output_images_s1\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load metadata\n",
    "metadata = pd.read_csv(metadata_file_path)\n",
    "metadata['Absolute Path'] = metadata['File Location'].apply(lambda x: os.path.join(base_dir, x.lstrip(\".\\\\\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2edd9502-a9fb-4d74-84f9-5813db059c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7639df1bfad5459ebaa3a5bf71cbb816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing DICOM folders:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in divide\n",
      "invalid value encountered in cast\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (6852,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 74\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError processing folder \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Convert to NumPy arrays\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m X_images \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, images[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], images[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     75\u001b[0m y_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(labels)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Print summary\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (6852,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pydicom import dcmread\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Define paths\n",
    "metadata_file_path = r\"D:\\\\PROJECTS_FINAL\\\\Cancer Treatment Prediction\\\\final stuff\\\\manifest-1732777365016\\\\metadata.csv\"\n",
    "base_dir = r\"D:\\\\PROJECTS_FINAL\\\\Cancer Treatment Prediction\\\\final stuff\\\\manifest-1732777365016\"\n",
    "processed_images_dir = os.path.join(base_dir, \"breast_cancer_images_png_s44\")\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(processed_images_dir, exist_ok=True)\n",
    "\n",
    "# Load metadata\n",
    "metadata = pd.read_csv(metadata_file_path)\n",
    "\n",
    "# Update paths in the metadata to absolute paths\n",
    "metadata['Absolute Path'] = metadata['File Location'].apply(lambda x: os.path.join(base_dir, x.lstrip(\".\\\\\")))\n",
    "\n",
    "images, labels = [], []\n",
    "\n",
    "# Process each folder listed in the metadata\n",
    "for folder_path in tqdm(metadata['Absolute Path'], desc=\"Processing DICOM folders\"):\n",
    "    try:\n",
    "        if not os.path.exists(folder_path):\n",
    "            print(f\"Folder not found: {folder_path}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "            if not file_name.endswith(\".dcm\"):\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Read DICOM file\n",
    "                dicom = dcmread(file_path)\n",
    "                if 'PixelData' not in dicom:\n",
    "                    print(f\"No PixelData in {file_path}, skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # Apply rescale slope and intercept if available\n",
    "                pixel_array = dicom.pixel_array\n",
    "                if hasattr(dicom, \"RescaleSlope\") and hasattr(dicom, \"RescaleIntercept\"):\n",
    "                    slope = dicom.RescaleSlope\n",
    "                    intercept = dicom.RescaleIntercept\n",
    "                    pixel_array = pixel_array * slope + intercept\n",
    "\n",
    "                # Normalize to 0-255 for PNG visualization\n",
    "                pixel_array = np.clip(pixel_array, np.min(pixel_array), np.max(pixel_array))  # Clip to valid range\n",
    "\n",
    "                # Check if the range is valid\n",
    "                if np.max(pixel_array) == np.min(pixel_array):\n",
    "                    print(f\"Invalid range detected in {file_path}. Setting image to zeros.\")\n",
    "                    pixel_array = np.zeros_like(pixel_array)  # Avoid divide-by-zero\n",
    "                else:\n",
    "                    pixel_array = (pixel_array - np.min(pixel_array)) / (np.max(pixel_array) - np.min(pixel_array))  # Normalize to 0-1\n",
    "\n",
    "                pixel_array = (pixel_array * 255).astype(np.uint8)  # Scale to 0-255\n",
    "\n",
    "                # Resize the image to ensure consistent dimensions\n",
    "                img = Image.fromarray(pixel_array).resize((512, 512))\n",
    "\n",
    "                # Save image as PNG\n",
    "                png_file_name = f\"{os.path.basename(folder_path)}_{file_name.replace('.dcm', '.png')}\"\n",
    "                img.save(os.path.join(processed_images_dir, png_file_name))\n",
    "\n",
    "                # Append to lists\n",
    "                images.append(np.array(img))\n",
    "                labels.append(0)  # Placeholder label\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing folder {folder_path}: {e}\")\n",
    "\n",
    "# Verify that all images have consistent shapes\n",
    "image_shapes = [img.shape for img in images]\n",
    "if len(set(image_shapes)) > 1:\n",
    "    print(f\"Inconsistent image shapes detected: {set(image_shapes)}\")\n",
    "    raise ValueError(\"All images must have the same shape.\")\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X_images = np.array(images).reshape(-1, 512, 512, 1)  # Reshape to 4D array\n",
    "y_images = np.array(labels)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Processed {len(X_images)} images.\")\n",
    "print(f\"Processed {len(y_images)} labels.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6045dfd4-c3f1-4776-a563-132c27964749",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images, masks, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data = [{\"image\": img, \"label\": mask} for img, mask in zip(X_train, y_train)]\n",
    "test_data = [{\"image\": img, \"label\": mask} for img, mask in zip(X_test, y_test)]\n",
    "\n",
    "train_transforms = Compose([\n",
    "    EnsureChannelFirst(),\n",
    "    ScaleIntensity(),\n",
    "    Resize((512, 512)),\n",
    "    EnsureType()\n",
    "])\n",
    "\n",
    "test_transforms = Compose([\n",
    "    EnsureChannelFirst(),\n",
    "    ScaleIntensity(),\n",
    "    Resize((512, 512)),\n",
    "    EnsureType()\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = Dataset(data=train_data, transform=train_transforms)\n",
    "test_dataset = Dataset(data=test_data, transform=test_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fcbd97-8dd9-40d4-b481-24384d877248",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = UNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").to(device)\n",
    "\n",
    "loss_function = DiceLoss(sigmoid=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc294f6c-60bc-4f5c-aa50-4cac3fff77dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "val_interval = 2\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch_data in train_loader:\n",
    "        inputs, labels = batch_data[\"image\"].to(device), batch_data[\"label\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} average loss: {epoch_loss / len(train_loader)}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_data in test_loader:\n",
    "                val_inputs, val_labels = val_data[\"image\"].to(device), val_data[\"label\"].to(device)\n",
    "                val_outputs = sliding_window_inference(val_inputs, (128, 128), 4, model)\n",
    "        print(f\"Validation performed for epoch {epoch + 1}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bf7f5f-6243-4249-8baa-cc3a9ed34275",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "characteristics = []\n",
    "\n",
    "for idx, test_sample in enumerate(test_loader):\n",
    "    test_image = test_sample[\"image\"].to(device)\n",
    "    test_output = sliding_window_inference(test_image, (128, 128), 4, model).detach().cpu().numpy()\n",
    "\n",
    "    for i in range(len(test_image)):\n",
    "        img = test_image[i, 0].cpu().numpy()\n",
    "        pred = test_output[i, 0]\n",
    "\n",
    "        # Binarize prediction\n",
    "        pred_mask = (pred > 0.5).astype(np.uint8)\n",
    "        labeled_mask = label(pred_mask)\n",
    "        regions = regionprops(labeled_mask)\n",
    "\n",
    "        # Draw bounding boxes\n",
    "        for region in regions:\n",
    "            minr, minc, maxr, maxc = region.bbox\n",
    "            img[minr:maxr, [minc, maxc]] = 1  # Vertical Lines\n",
    "            img[[minr, maxr], minc:maxc] = 1  # Horizontal Lines\n",
    "\n",
    "            characteristics.append({\n",
    "                \"Image Index\": idx,\n",
    "                \"Region Area\": region.area,\n",
    "                \"Bounding Box\": region.bbox,\n",
    "                \"Centroid\": region.centroid,\n",
    "            })\n",
    "\n",
    "        # Save the image\n",
    "        plt.imsave(os.path.join(output_dir, f\"tumor_detected_{idx}.png\"), img, cmap=\"gray\")\n",
    "\n",
    "# Save characteristics to CSV\n",
    "pd.DataFrame(characteristics).to_csv(os.path.join(output_dir, \"tumor_characteristics.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d5ca51-818a-422e-b442-483ab59de6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(output_dir, \"tumor_segmentation_unet.pth\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
